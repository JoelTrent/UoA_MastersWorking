using ForwardDiff
# using Memoize

# memoizing doesn't appear to have a performance advantage in this situation for small number of parameters (is a performance hit in fact) - may be advantageous for a larger number of parameters
# @memoize function invCovariance(Γ::Matrix{T}, θIndexes::Vector{Int}) where T<:Float64
#     return inv(Γ[θIndexes, θIndexes]) 
# end
# function analytic_ellipse_loglike(θ::Vector{T}, θIndexes::Vector{Int}, 
#                                     θmle::Vector{T}, Γ::Matrix{T}) where T<:Float64
#     return -0.5 * (θ-θmle[θIndexes])' * invCovariance(Γ, θIndexes) * (θ-θmle[θIndexes])
# end

# Analytic ellipse log-likelihood has no knowledge of lower and upper bounds on parameters. 
# Hence profiles generated by optimising out the nuisance parameters for a given
# interest parameter may look different if the analytical profile enters space
# where a bound would be active
function analytic_ellipse_loglike(θ::Vector{T}, θIndexes::Vector{Int}, 
    θmle::Vector{T}, Γ::Matrix{T}) where T<:Float64
    return -0.5 * (θ-θmle[θIndexes])' * inv(Γ[θIndexes, θIndexes])  * (θ-θmle[θIndexes])
end

function ellipse_loglike(θ::Vector{T}, θmle::Vector{T}, H::Matrix{T})::Float64 where T<:Float64
    return -0.5 * ((θ - θmle)' * H * (θ - θmle))
end

function ellipse_like(θ::Vector{T}, θmle::Vector{T}, H::Matrix{T}) where T<:Real
    return exp(ellipse_loglike(θ, θmle, H))
end

function getMLE_hessian_and_covariance(f::Function, θmle::Vector{<:Float64})

    H = -ForwardDiff.hessian(f, θmle)

    # if inverse fails then may have locally non-identifiable parameter OR parameter is
    # a delta distribution given data.
    Γ = inv(H)

    return H, Γ
end